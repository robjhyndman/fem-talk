---
title: Probabilistic Forecast Reconciliation For Emergency Services Demand
author: Rob J Hyndman\newline Bahman Rostami-Tabar
pdf-engine: pdflatex
fig-width: 9
fig-height: 4.5
format:
  beamer:
    theme: monash
    aspectratio: 169
    fontsize: 14pt
    section-titles: false
    knitr:
      opts_chunk:
        dev: "CairoPDF"
include-in-header: header.tex
keep-tex: true
toc: false
execute:
  echo: false
  message: false
  warning: false
  cache: true
---

```{r}
#| label: setup
#| cache: false
source(here::here("setup.R"))
```


## Wales Health Board Areas

\placefig{3.3}{1.2}{width=7.8cm}{Map-of-Wales-Health-Boards}

## Data

```{r}
#| label: data
incident_gthf <- readr::read_rds(here::here("data/incidents_gt.rds"))
```



* Daily number of attended incidents:\newline 1 October 2015 -- 31 July 2019
* Disaggregated by:
  * control area
  * health board
  * priority
  * nature of incidents
* `r label_comma()(NROW(incident_gthf))` rows observations from `r label_comma()(NROW(attributes(incident_gthf)$key))` time series.

## Data structure

```{r}
#| label: data_structure
#| include: false
data <- data.frame(
  level1 = "Total",
  level2 = c(
    "Central & West", "Central & West", "Central & West",
    "North", "South & East", "South & East", "South & East"
  ),
  level3 = c("HD", "AB", "PO", "BC", "CV", "CT", "AB")
)
# transform it to a edge list!
edges_level1_2 <- data |>
  select(level1, level2) |>
  unique() |>
  rename(from = level1, to = level2)
edges_level2_3 <- data |>
  select(level2, level3) |>
  unique() |>
  rename(from = level2, to = level3)
Cairo::CairoPDF(here::here("figs/group.pdf"), width = 6, height = 6)
rbind(edges_level1_2, edges_level2_3) |>
  igraph::graph_from_data_frame() |>
  ggraph::ggraph(layout = "dendrogram", circular = FALSE) +
  ggraph::geom_edge_diagonal() +
  ggraph::geom_node_point(color = "#dddddd", size = 10) +
  ggraph::geom_node_text(
    aes(label = c(
      "All country",
      "Central & West", "North", "South & East",
      "HD", "AB", "PO", "BC", "CV", "CT", "AB"
    ))
  ) +
  theme_void() +
  theme(
    # panel.background = element_rect(fill = "transparent"), # transparent panel bg
    plot.background = element_rect(fill = "transparent"), # transparent plot bg
  )
crop::dev.off.crop()
```

\placefig{0.3}{1.5}{width=7cm}{group.pdf}
\placefig{7.5}{1.5}{width=7.7cm}{group.png}

## Data structure
\fontsize{10}{11}\sf

```{r}
#| label: data_structure_table
agg_level <- tibble::tribble(
  ~Level, ~`Number of series`,
  "All country", 1,
  "Control", 3,
  "Health board", 7,
  "Priority", 3,
  "Priority * Control", 9,
  "Priority * Health board", 21,
  "Nature of incident", 35,
  "Nature of incident * Control", 105,
  "Nature of incident * Health board", 245,
  "Priority * Nature of incident", 104,
  "Control * Priority * Nature of incident", 306,
  "Control * Health board * Priority * Nature of incident (Bottom level)", 691,
  "Total", 1530
)
knitr::kable(agg_level, booktabs = TRUE, position = "left", linesep = "") |>
  kable_classic(full_width = FALSE)
```

## Data
\fontsize{10}{10}\sf

```{r}
incident_gthf
```

## Data
\fontsize{10}{10}\sf

```{r}
incident_gthf  |>
  arrange(date, region, category, nature, lhb)  |>
  mutate(category = recode(category, RED = "Red", AMB = "Amber", GRE = "Green"))
```

```{r}
#| label: time_plots
gglabs <- ggplot2::labs(x = "Date", y = "Incidents")
p_total <- incident_gthf |>
  filter(is_aggregated(region) & is_aggregated(lhb) & is_aggregated(category) & is_aggregated(nature)) |>
  autoplot(incident) +
  gglabs + ggtitle("Total incidents")

p_control <- incident_gthf |>
  filter(!is_aggregated(region) & !is_aggregated(lhb) & is_aggregated(category) & is_aggregated(nature)) |>
  as_tibble() |>
  select(-nature, -category) |>
  group_by(date, region) |>
  summarise(incident = sum(incident), .groups = "drop") |>
  ggplot(aes(x = date, y = incident, color = factor(region))) +
  geom_line() +
  gglabs + ggtitle("Total incidents by control areas") +
  labs(color = "Control")

p_board <- incident_gthf |>
  filter(!is_aggregated(region) & !is_aggregated(lhb) & is_aggregated(category) & is_aggregated(nature)) |>
  as_tibble() |>
  select(-nature, -category) |>
  ggplot(aes(x = date, y = incident, color = factor(lhb))) +
  geom_line() +
  gglabs + ggtitle("Total incidents by health boards") +
  labs(color = "Health board")

p_priority <- incident_gthf |>
  filter(is_aggregated(region) & is_aggregated(lhb) & !is_aggregated(category) & is_aggregated(nature)) |>
  mutate(
    category = recode(category, RED = "Red", AMB = "Amber", GRE = "Green"),
    category = factor(category, levels = c("Red", "Amber", "Green"))
  ) |>
  as_tibble() |>
  select(-nature, -region) |>
  ggplot(aes(x = date, y = incident, color = factor(category))) +
  geom_line() +
  scale_color_manual(values = c(Red = "#ff3300", Amber = "#E69f00", Green = "#009e73")) +
  gglabs + ggtitle("Total incidents by priority") +
  labs(color = "Priority")

p_nature1 <- incident_gthf |>
  filter(is_aggregated(region) & is_aggregated(lhb) & is_aggregated(category) & !is_aggregated(nature)) |>
  as_tibble() |>
  mutate(nature = stringr::str_pad(as.character(nature), width = 12, side = "right")) |>
  group_by(date, nature, lhb) |>
  summarise(incident = sum(incident), .groups = "drop") |>
  ggplot(aes(x = date, y = incident, color = nature)) +
  geom_line() +
  gglabs + ggtitle("Total incidents by nature of incident") +
  labs(color = "Nature of incident") +
  ylim(0,260)

top_cat <- incident_gthf |>
  as_tibble() |>
  filter(!is_aggregated(nature)) |>
  group_by(nature) |>
  summarise(incident = sum(incident), .groups = "drop") |>
  arrange(desc(incident)) |>
  head(3) |>
  pull(nature) |>
  as.character()
selected_nature <- c("CHESTPAIN", "STROKECVA", "BREATHING", "ABDOMINAL")
p_nature2 <- incident_gthf |>
  filter(is_aggregated(region) & is_aggregated(lhb) & is_aggregated(category) & !is_aggregated(nature)) |>
  as_tibble() |>
  mutate(nature = as.character(nature)) |>
  filter(nature %in% selected_nature) |>
  group_by(date, nature, lhb) |>
  summarise(incident = sum(incident), .groups = "drop") |>
  ggplot(aes(x = date, y = incident, color = nature)) +
  geom_line() +
  gglabs + ggtitle("Total incidents by nature of incident") +
  labs(color = "Nature of incident") +
  ylim(0,260)

p <- patchwork::align_patches(p_total, p_control, p_board, p_priority, p_nature1, p_nature2)
for(i in seq_along(p)) {
  filename <- here::here(paste0("figs/time_plots",i,".pdf"))
  Cairo::CairoPDF(filename, width = 9, height = 4.3)
  print(p[[i]])
  crop::dev.off.crop()
}
```

## Aggregated daily incidents
\vspace*{0.2cm}

\only<1>{\centerline{\includegraphics[width=15.8cm]{figs/time_plots1.pdf}}}
\only<2>{\centerline{\includegraphics[width=15.8cm]{figs/time_plots2.pdf}}}
\only<3>{\centerline{\includegraphics[width=15.8cm]{figs/time_plots3.pdf}}}
\only<4>{\centerline{\includegraphics[width=15.8cm]{figs/time_plots4.pdf}}}
\only<5>{\centerline{\includegraphics[width=15.8cm]{figs/time_plots5.pdf}}}
\only<6>{\centerline{\includegraphics[width=15.8cm]{figs/time_plots6.pdf}}}

## Forecasting methods

1. **Naïve**: Empirical distribution of past daily attended incidents.
2. **ETS**: Exponential Smoothing State Space models.
3. **GLM**: Poission Regression with spline trend, day of the week, annual Fourier seasonality, public holidays, school holidays, Christmas Day, New Year's Day.
4. **TSGLM**: Poisson Regression with same covariates plus three autoregressive terms.
5. **Ensemble**: Mixture distribution of 1--4.

## Notation

\begin{textblock}{8.5}(0.2,1.5)
Every collection of time series with linear constraints can be written as
\centerline{\colorbox[RGB]{210,210,210}{$\bY_{t}=\color{blue}\bS\color{red}\bm{b}_{t}$}}
\vspace*{-0.9cm}\begin{itemize}\parskip=0cm\itemsep=0cm
\item $\by_t=$ vector of all series at time $t$
\item $ y_{\text{Total},t}= $ aggregate of all series at time
$t$.
\item $ y_{X,t}= $ value of series $X$ at time $t$.
\item $\color{red}{\bm{b}_t}=$ vector of most disaggregated series at time $t$
\item $\color{blue}{\bS}=$ ``summing matrix'' containing the linear constraints.
\end{itemize}
\end{textblock}

\begin{textblock}{5.7}(11.4,0.1)
\begin{minipage}{4cm}
\begin{block}{}\centering
\begin{tikzpicture}
\tikzstyle{every node}=[ellipse,draw,fill=red!15,inner sep=2pt]
\tikzstyle[level distance=.3cm]
\tikzstyle[sibling distance=12cm]
\tikzstyle{level 1}=[sibling distance=10mm,font=\small,set style={{every node}+=[fill=blue!15]}]
\node{Total}[edge from parent fork down]
 child {node {A}
 }
 child {node {B}
 }
 child {node {C}
 };
\end{tikzpicture}
\end{block}
\end{minipage}
\end{textblock}

\only<1>{\begin{textblock}{5.7}(9.4,2.8)\fontsize{14}{15}\sf
\begin{align*}
\bY_{t}&= \begin{pmatrix}
  y_{\text{Total},t}\\
  y_{A,t}\\
  y_{B,t}\\
  y_{C,t}
  \end{pmatrix}  \\
  &= {\color{blue}\underbrace{\begin{pmatrix}
                1 & 1 & 1 \\
                1 & 0 & 0 \\
                0 & 1 & 0\\
                0 & 0 & 1
                \end{pmatrix}}_{\bS}}
     {\color{red}\underbrace{\begin{pmatrix}
       y_{A,t}\\y_{B,t}\\y_{C,t}
       \end{pmatrix}}_{\bm{b}_{t}}}
\end{align*}
\end{textblock}}
\only<2>{\begin{textblock}{5.7}(9.4,3.2)\fontsize{14}{15}\sf
\begin{alertblock}{}
\begin{itemize}\itemsep=0.1cm
\item Base forecasts: $\hat{\bm{y}}_{T+h|T}$
\item Reconciled forecasts: $\tilde{\bm{y}}_{T+h|T}=\bS\bm{G}\hat{\bm{y}}_{T+h|T}$
\item MinT: $\bG = (\bS'\bm{W}_h^{-1}\bS)^{-1}\bS'\bm{W}_h^{-1}$ where $\bm{W}_h$ is covariance matrix of base forecast errors.
\end{itemize}
\end{alertblock}
\end{textblock}}

## Nonparametric bootstrap reconciliation

* Fit model to all series and store the residuals as $\underaccent{\tilde}{\bm{\varepsilon}}_t$.
* These should be serially uncorrelated but cross-sectionally correlated.
* Draw iid samples from $\underaccent{\tilde}{\bm{\varepsilon}}_1,\dots,\underaccent{\tilde}{\bm{\varepsilon}}_T$ with replacement.
* Simulate future sample paths for model using the bootstrapped residuals.
* Reconcile each sample path using MinT.
* Combine the reconciled sample paths to form a mixture distribution at each forecast horizon.

## Boostrapping residuals

```{r}
#| label: sim_bootstrap
#| include: false
p <- tidyr::expand_grid(
    time = seq(100),
    series = seq(20)
  ) |>
  mutate(res = rnorm(n())) |>
  ggplot(aes(x=time, y=series, fill=res)) +
  geom_tile() +
  scale_y_continuous(breaks = seq(20), minor_breaks = NULL, expand=c(0,0)) +
  guides(fill = "none")
Cairo::CairoPDF(file="figs/sim_bootstrap.pdf", width=8, height=4)
  print(p)
crop::dev.off.crop()
slices <- sample(seq(100), replace = TRUE, size = 20)
for(i in seq_along(slices)) {
  Cairo::CairoPDF(file=paste0("figs/sim_bootstrap_", i, ".pdf"), width=8, height=4)
    print(p +
      geom_rect(aes(xmin = slices[i], xmax = slices[i]+0.9, ymin = 0.5, ymax = 20.5),
                 fill = "transparent", col="white"))
  crop::dev.off.crop()
}
```

\vspace*{0.2cm}
\centerline{\includegraphics[width=15.5cm]{figs/sim_bootstrap.pdf}}

## Boostrapping residuals

\vspace*{0.2cm}
\centerline{
\animategraphics[loop,autoplay,width=15.5cm]{10}{figs/sim_bootstrap_}{1}{20}
}


## Performance evaluation

* Ten-fold time series cross-validation
* Forecast horizon of 1--84 days
* Each training set contains an additional 42 days.
* Forecasts at 43--84 days correspond to planning horizon.

```{r}
#| label: cv1
#| echo: false
#| fig-height: 2.7
.lines <- 10
.init <- 30
.step <- 6
h <- 7:12
max_t <- .init + .step*(.lines - 1) + max(h)
expand.grid(
    time = seq(max_t),
    .id = seq(.lines)
  ) |>
  mutate(
    min_h = (.id-1) * .step + .init + min(h),
    max_h =  (.id-1) * .step + .init + max(h),
    observation = case_when(
      time <= ((.id - 1) * .step + .init) ~ "train",
      time < min_h ~ "test1",
      time <= max_h ~ "test2",
      TRUE ~ "unused"
    )
  ) |>
  ggplot(aes(x = time, y = .id)) +
  geom_segment(
    aes(x = 0, xend = max_t+1, y = .id, yend = .id),
    arrow = arrow(length = unit(0.015, "npc")),
    col = "black", linewidth = .25
  ) +
  geom_point(aes(col = observation), size = 2) +
  scale_y_reverse() +
  scale_colour_manual(values = c(train = "#0072B2", test1 = "#d59771", test2 = "#D55E00", unused = "gray")) +
  theme_void() +
  guides(colour = "none") +
  labs(x = "weeks", y = "") +
  theme_void() +
  theme(
    axis.title = element_text(),
    plot.background = element_rect(fill = "#fafafa", color = "#fafafa")
  )
```


```{r}
#| label: results
#| include: false
rmsse <- readr::read_rds(here::here("results/rmsse.rds")) |>
  mutate(msse = rmsse^2) |>
	mutate(model = if_else(model == "", "ensemble2", model))
mase <- readr::read_rds(here::here("results/mase.rds")) |>
		mutate(model = if_else(model == "", "ensemble2", model))
crps <- readr::read_rds(here::here("results/crps.rds")) |>
	mutate(model = if_else(model == "", "ensemble2", model)) |>
  pivot_wider(names_from = model, values_from = crps) |>
  group_by(method, h, series) |>
  mutate(across(where(is.numeric), ~ .x / naiveecdf)) |>
  ungroup() |>
  pivot_longer(ensemble2:tscount, names_to = "model", values_to = "crps")
```

```{r}
#| label: results_graph
accuracy <- bind_rows(
  rmsse |> mutate(measure = "msse", accuracy = rmsse^2),
  mase |> mutate(measure = "mase", accuracy = mase),
  crps |> mutate(measure = "crps", accuracy = crps),
) |>
  select(-rmsse, -mase, -crps) |>
	filter(model != "ensemble2", model != "qcomb")

# Plot of average accuracy vs week for each method for Total
acc_summary <- accuracy |>
  filter(
    series %in% c("Total", "Control areas", "Health boards"),
    method == "mint",
  ) |>
  mutate(model = case_when(
    model == "naiveecdf" ~ "Naïve",
    model == "ets" ~ "ETS",
    model == "tscount" ~ "TSGLM",
    model == "iglm" ~ "GLM",
    model == "ensemble" ~ "Ensemble"
  )) |>
  mutate(
    measure = factor(measure, levels = c("mase", "msse", "crps"), labels = c("MASE", "MSSE", "CRPS")),
    series = factor(series, levels = c("Total", "Control areas", "Health boards")),
    model = factor(model, levels = c("Naïve", "ETS", "TSGLM", "GLM", "Ensemble")),
    week = factor(trunc((h - 1) / 7) + 1)
  ) |>
  group_by(week, model, measure, series) |>
  summarise(accuracy = mean(accuracy), .groups = "drop")
```

## Forecast accuracy: 43--84 days ahead
\fontsize{10}{12}\sf

```{r}
#| label: results_table_msse
# Set minimum in column to bold
set_to_bold <- function(table) {
  for (i in 3:6) {
    best <- which.min(table[[i]])
    table[[i]] <- sprintf(table[[i]], fmt = "%1.3f")
    table[[i]][best] <- cell_spec(table[[i]][best], bold = TRUE)
  }
  return(table)
}

msse1 <- rmsse |>
  filter(
    method %in% c("mint", "base"),
    model != "qcomb", model != "ensemble2",
    h > 42
  ) |>
  mutate(
    model = factor(model,
      levels = c("naiveecdf", "ets", "iglm", "tscount", "ensemble"),
      labels = c("Naïve", "ETS", "GLM", "TSGLM", "Ensemble")
    ),
    method = factor(method, levels = c("base", "mint"), labels = c("Base", "MinT")),
  ) |>
  group_by(method, model, series) |>
  summarise(msse = mean(msse), .groups = "drop") |>
  pivot_wider(names_from = series, values_from = msse) |>
  select(Method = method, Model = model, Total, `Control areas`, `Health boards`, Bottom) |>
  set_to_bold()
  msse1  |>
    select(-Bottom)  |>
    kbl(booktabs = TRUE, escape = FALSE, align = "llrrr") |>
    add_header_above(c(" " = 2, "MSSE" = 3)) |>
    kable_styling(position = "left", latex_options = c("hold_position"))
```

\begin{textblock}{4.2}(11.6, 1.2)
\begin{block}{}
\centerline{$\text{MSSE} = \text{mean}(q_{j}^2)$}
$$
  q^2_{j} = \frac{ e^2_{j}}
 {\displaystyle\frac{1}{T-7}\sum_{t=8}^T (y_{t}-y_{t-7})^2}
$$
\begin{itemize}
\item Observations: $y_1,\dots,y_T$.
\item Forecast errors: $e_{j}=y_{T+j}-\hat{y}_{T+j|T}$.
\end{itemize}
\end{block}
\end{textblock}

## Forecast accuracy: 43--84 days ahead
\fontsize{10}{12}\sf

```{r}

crps1 <- readr::read_rds(here::here("results/crps.rds")) |>
  filter(
    method %in% c("mint", "base"),
    model != "qcomb", model != "ensemble2",
    h > 42
  ) |>
  mutate(
    model = factor(model,
      levels = c("naiveecdf", "ets", "iglm", "tscount", "ensemble"),
      labels = c("Naïve", "ETS", "GLM", "TSGLM", "Ensemble")
    ),
    method = factor(method, levels = c("base", "mint"), labels = c("Base", "MinT"))
  ) |>
  group_by(method, model, series) |>
  summarise(crps = mean(crps), .groups = "drop") |>
  pivot_wider(names_from = series, values_from = crps) |>
  select(Method = method, Model = model, Total, `Control areas`, `Health boards`, Bottom) |>
  set_to_bold()
crps1  |>
  select(-Bottom)  |>
  kbl(booktabs = TRUE, escape = FALSE, align = "llrrr") |>
  add_header_above(c(" " = 2, "CRPS" = 3)) |>
  kable_styling(position = "left", latex_options = c("hold_position"))
```

\begin{textblock}{4.2}(11.6, 1.2)
\begin{block}{}
\centerline{$\text{CRPS} = \text{mean}(p_j)$}
$$
  p_j = \int_{-\infty}^{\infty} \left(G_j(x) - F_j(x)\right)^2dx,
$$
\begin{itemize}
\item $G_j(x)=$ forecast distribution for forecast horizon $j$
\item $F_j(x)=$ empirical distribution for same period
\end{itemize}
\end{block}
\end{textblock}

## Conclusions

* Ensemble mixture distributions give better forecasts than any component methods.
* Forecast reconciliation improves forecast accuracy, even when some component methods are quite poor.
* The ensemble without the Naïve method was worse.
* Forecast reconciliation allows coordinated planning and resource allocation.

\only<2>{\begin{textblock}{14}(.9,6.8)
\begin{block}{}
\fontsize{13}{14}\sf
\begin{multicols}{2}
\begin{itemize}\parskip = 0cm\itemsep = 0.2cm
\item[\faIcon{chalkboard-teacher}] \href{https://robjhyndman.com/asc2023}{robjhyndman.com/asc2023}
\item[{\faIcon[regular]{file-alt}}] \href{https://robjhyndman.com/fems}{robjhyndman.com/fems}
\item[\faIcon{mastodon}] \href{https://aus.social/@robjhyndman}{aus.social/@robjhyndman}
\item[\faIcon{envelope}] \href{mailto:rob.hyndman@monash.edu}{rob.hyndman@monash.edu}
\end{itemize}
\end{multicols}
\end{block}
\end{textblock}}
